{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1716790119.092817\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bam/.store/aienv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "HUGGING_FACE_API_KEY = \"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\"\n",
    "\n",
    "import torch\n",
    "torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_id = \"databricks/dolly-v2-3b\"\n",
    "filenames = [\n",
    "        \"config.json\", \"instruct_pipeline.py\", \"pytorch_model.bin\", \n",
    "        \"special_tokens_map.json\", \"tokenizer.json\", \"tokenizer_config.json\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bam/.cache/huggingface/hub/models--databricks--dolly-v2-3b/snapshots/f6c9be08f16fe4d3a719bee0a4a7c7415b5c65df/config.json\n",
      "/home/bam/.cache/huggingface/hub/models--databricks--dolly-v2-3b/snapshots/f6c9be08f16fe4d3a719bee0a4a7c7415b5c65df/instruct_pipeline.py\n",
      "/home/bam/.cache/huggingface/hub/models--databricks--dolly-v2-3b/snapshots/f6c9be08f16fe4d3a719bee0a4a7c7415b5c65df/pytorch_model.bin\n",
      "/home/bam/.cache/huggingface/hub/models--databricks--dolly-v2-3b/snapshots/f6c9be08f16fe4d3a719bee0a4a7c7415b5c65df/special_tokens_map.json\n",
      "/home/bam/.cache/huggingface/hub/models--databricks--dolly-v2-3b/snapshots/f6c9be08f16fe4d3a719bee0a4a7c7415b5c65df/tokenizer.json\n",
      "/home/bam/.cache/huggingface/hub/models--databricks--dolly-v2-3b/snapshots/f6c9be08f16fe4d3a719bee0a4a7c7415b5c65df/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "        downloaded_model_path = hf_hub_download(\n",
    "                    repo_id=model_id,\n",
    "                    filename=filename,\n",
    "                    token=HUGGING_FACE_API_KEY\n",
    "        )\n",
    "        print(downloaded_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "\n",
    "device1=\"cuda\"\n",
    "device2=\"cpu\"\n",
    "\n",
    "device_map = {\n",
    "\"transformer.word_embeddings\": device1,\n",
    "\"transformer.word_embeddings_layernorm\": device1,\n",
    "\"lm_head\": device1,\n",
    "\"transformer.h\": device1,\n",
    "\"transformer.ln_f\": device1,\n",
    "\"model.embed_tokens\": device1,\n",
    "\"model.layers\":device1,\n",
    "\"model.norm\":device1\n",
    "}\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(llm_int8_enable_fp32_cpu_offload=True,load_in_4bit=True)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, legacy=False, local_files_only=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, local_files_only=True,low_cpu_mem_usage=True, device_map=\"auto\",quantization_config=quantization_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bam/.store/aienv/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What are competitors to Apache Kafka?\\n\\nApache Kafka is not a competitor to any other streaming system. It is a completely different architecture and a different paradigm.\\n\\nApache Kafka is a distributed system that is optimized for a specific use case: streaming data. It is not a data store, it is not a data pipeline, it is not a data warehouse, and it is not a data lake. It is a streaming system.\\n\\nOther streaming systems exist, but none of them are optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data. They are optimized for data pipelines, data warehouses, or data lakes.\\n\\nOther streaming systems are not optimized for streaming data.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=1000)   \n",
    "\n",
    "pipeline(\"What are competitors to Apache Kafka?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many states are there in India?\n",
      "\n",
      "There are 10 states and 1 union territory in India.\n",
      "\n",
      "Which states are the most populous?\n",
      "\n",
      "The most populous states are:\n",
      "\n",
      "1. Maharashtra\n",
      "2. Gujarat\n",
      "3. Uttar Pradesh\n",
      "4. Tamil Nadu\n",
      "5. West Bengal\n",
      "6. Karnataka\n",
      "7. Delhi\n",
      "8. Telangana\n",
      "9. Andhra Pradesh\n",
      "10. Kerala\n",
      "\n",
      "The states with the largest populations are:\n",
      "\n",
      "1. Maharashtra\n",
      "2. Gujarat\n",
      "3. Uttar Pradesh\n",
      "4. Telangana\n",
      "5. Andhra Pradesh\n",
      "6. Kerala\n",
      "7. Karnataka\n",
      "8. Delhi\n",
      "\n",
      "The union territory with the largest population is:\n",
      "\n",
      "1. Delhi\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Sikkim\n",
      "4. Ladakh\n",
      "5. Union Territory of Chandigarh\n",
      "6. Puducherry\n",
      "7. Jammu and Kashmir\n",
      "8. Ladakh\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Sikkim\n",
      "4. Puducherry\n",
      "5. Union Territory of Chandigarh\n",
      "6. Jammu and Kashmir\n",
      "\n",
      "The union territories with the largest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Sikkim\n",
      "4. Puducherry\n",
      "5. Union Territory of Chandigarh\n",
      "6. Jammu and Kashmir\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Delhi\n",
      "2. Sikkim\n",
      "3. Puducherry\n",
      "4. Union Territory of Chandigarh\n",
      "5. Jammu and Kashmir\n",
      "\n",
      "The union territories with the largest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Sikkim\n",
      "4. Union Territory of Chandigarh\n",
      "5. Jammu and Kashmir\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Delhi\n",
      "2. Sikkim\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the largest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Delhi\n",
      "2. Sikkim\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the largest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Delhi\n",
      "2. Sikkim\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the largest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Delhi\n",
      "2. Sikkim\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the largest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Delhi\n",
      "2. Sikkim\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the largest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Delhi\n",
      "2. Sikkim\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the largest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Delhi\n",
      "2. Sikkim\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the largest populations are:\n",
      "\n",
      "1. Chandigarh\n",
      "2. Delhi\n",
      "3. Union Territory of Chandigarh\n",
      "4. Jammu and Kashmir\n",
      "\n",
      "The union territories with the smallest populations are:\n",
      "\n",
      "1. Delhi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=pipeline)\n",
    "result = llm.invoke(\"How many states are there in India\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken:181.18804788589478\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "end_time = time.time()\n",
    "print(\"Total Time taken:\" +  str(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
